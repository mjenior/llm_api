{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d824fc2",
   "metadata": {},
   "source": [
    "# Example Worflow Using Multiple LLM Agents"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf7409c7-3c2b-4ec5-aff2-f869d848f80d",
   "metadata": {},
   "source": [
    "This notebook is an example of how you can use the <llm_api> package to quickly create specialized LLM agents to complete tasks alone or in cooperation with other agents you create. Each agent initialized below makes use of several of the built-in options in different ways tailored to the specific task they are meant for. By default for all agents, all text processing and response text are reported to StdOut (verbose=True) and saved to a log file (logging=True). Any generated code snippets are also saved to executable scripts in a new code folder in your working directory (save_code=True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7907ea1d-e1d9-4b83-8fb2-6fd503095d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core class\n",
    "from llm_api.core import OpenAIQueryHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210ffcc6",
   "metadata": {},
   "source": [
    "## Initialize distinct agents with unique expertise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78ec5244-6889-4854-a27e-bed1e5e6e671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent parameters:\n",
      "    Model: gpt-4o-mini\n",
      "    Role: Computational Biologist\n",
      "    Chain-of-thought: True\n",
      "    Prompt refinement: True\n",
      "    Associative glyphs: True\n",
      "    Response iterations: 1\n",
      "    Subdirectory scanning: False\n",
      "    Time stamp: 2025-01-28_10-57-47\n",
      "    Seed: 42\n",
      "    Text logging: True\n",
      "    Snippet logging: True\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Computational biologist\n",
    "compbio = OpenAIQueryHandler(role=\"analyst\", refine=True, chain_of_thought=True, glyph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc97852c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent parameters:\n",
      "    Model: gpt-4o-mini\n",
      "    Role: Refactoring Expert\n",
      "    Chain-of-thought: False\n",
      "    Prompt refinement: False\n",
      "    Associative glyphs: False\n",
      "    Response iterations: 1\n",
      "    Subdirectory scanning: False\n",
      "    Time stamp: 2025-01-28_10-57-47\n",
      "    Seed: 42\n",
      "    Text logging: True\n",
      "    Snippet logging: True\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Code refactoring and formatting expert\n",
    "recode = OpenAIQueryHandler(role=\"refactor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db99dc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent parameters:\n",
      "    Model: gpt-4o-mini\n",
      "    Role: Unit Tester\n",
      "    Chain-of-thought: False\n",
      "    Prompt refinement: False\n",
      "    Associative glyphs: False\n",
      "    Response iterations: 1\n",
      "    Subdirectory scanning: False\n",
      "    Time stamp: 2025-01-28_10-57-47\n",
      "    Seed: 42\n",
      "    Text logging: True\n",
      "    Snippet logging: True\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Unit test generator\n",
    "tests = OpenAIQueryHandler(role=\"tester\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da8a0fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent parameters:\n",
      "    Model: gpt-4o-mini\n",
      "    Role: Writer\n",
      "    Chain-of-thought: False\n",
      "    Prompt refinement: False\n",
      "    Associative glyphs: True\n",
      "    Response iterations: 5\n",
      "    Subdirectory scanning: False\n",
      "    Time stamp: 2025-01-28_10-57-47\n",
      "    Seed: 42\n",
      "    Text logging: True\n",
      "    Snippet logging: True\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Creative science writer\n",
    "write = OpenAIQueryHandler(role=\"writer\", iterations=5, chain_of_thought=False, glyph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26a1ca67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent parameters:\n",
      "    Model: gpt-4o-mini\n",
      "    Role: Editor\n",
      "    Chain-of-thought: False\n",
      "    Prompt refinement: True\n",
      "    Associative glyphs: False\n",
      "    Response iterations: 1\n",
      "    Subdirectory scanning: False\n",
      "    Time stamp: 2025-01-28_10-57-47\n",
      "    Seed: 42\n",
      "    Text logging: True\n",
      "    Snippet logging: True\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Expert copy editor\n",
    "edit = OpenAIQueryHandler(role=\"editor\", refine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08c6b63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent parameters:\n",
      "    Model: gpt-4o-mini\n",
      "    Role: User-defined custom role\n",
      "    Chain-of-thought: False\n",
      "    Prompt refinement: True\n",
      "    Associative glyphs: False\n",
      "    Response iterations: 1\n",
      "    Subdirectory scanning: False\n",
      "    Time stamp: 2025-01-28_10-57-47\n",
      "    Seed: 42\n",
      "    Text logging: True\n",
      "    Snippet logging: True\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Custom role for condensing text into Slack posts\n",
    "role_text = \"\"\"\n",
    "You are an expert in condensing text and providing summaries.\n",
    "Begin by providing a brief summary of the text. Then, condense the text into a few key points. Finally, write a concise conclusion that captures the main ideas of the text.\n",
    "Remember to keep the summary clear, concise, and engaging.\n",
    "Keep posts to a maximum of 2 paragraphs of 3-4 sentences each.\n",
    "Add a @here mention at the beginning of the message to notify the channel members about the summary.\n",
    "\"\"\"\n",
    "slack = OpenAIQueryHandler(role=role_text, refine=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a07c3e3",
   "metadata": {},
   "source": [
    "## Submit requests to the new agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba4e1f7-4f0c-4d55-8942-8b7d113b3918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make initial request to first agent for computational biology project\n",
    "query = \"\"\"\n",
    "Write an analysis pipeline in python to assemble long nanopore reads into contigs and then align them to an annotated reference genome.\n",
    "Then identify all of the sequence variation present in the new genome that is not present in the reference.\n",
    "Additionally generate a figure from data generated during the alignment based on quality scores, and 2 more figures to help interpret the results at the end.\n",
    "\"\"\"\n",
    "compbio.request(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1e145f-a065-4ec2-acbf-268524275d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize and document any new code\n",
    "query = \"\"\"\n",
    "Refactor and format the following scripts for optimal efficiency, useability, and generalization:\n",
    "\n",
    "\"\"\"\n",
    "query += \" \".join(compbio.code_files)\n",
    "recode.request(query)\n",
    "\n",
    "# Add unit testing\n",
    "query = \"\"\"\n",
    "Generate unit tests for the following code:\n",
    "\n",
    "\"\"\"\n",
    "query += \" \".join(compbio.code_files)\n",
    "tests.request(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d690104-d6e9-44bb-b48e-922122d8aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilize the writer agent to generate an informed post on the background and utility of the newly created pipeline\n",
    "query = \"\"\"\n",
    "Write a biotechnology blog post about the pipeline described below.\n",
    "Include relevant background that would necessitate this type of analysis, and add at least one example use case for the workflow.\n",
    "Extrapolate how the pipeline may be useful in cell engineering efforts, and what future improvements could lead to with continued work.\n",
    "The resulting post should be at least 3 paragraphs long with 4-5 sentences in each.\n",
    "Speak in a conversational tone and cite all sources with biological relevance to you discussion.\n",
    "\"\"\"\n",
    "query = f\"{query}\\n{compbio.message}\"\n",
    "write.request(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3457bd15-07e1-4d20-b766-4bbb7f45cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the rough draft text to the editor agent to recieve a more finalize version\n",
    "edit.request(write.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98c02b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Slack post summarizing the finalized text\n",
    "slack.request(edit.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40ef4a4-3848-4605-8eca-61609911bb6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
