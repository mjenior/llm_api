# Code generated by gpt-4o

import requests
from bs4 import BeautifulSoup
import pandas as pd
import time

# List of URLs to scrape
urls = [
    'https://example-ecommerce.com/page1',
    'https://example-ecommerce.com/page2',
    # Add more URLs as needed
]

# A function that takes a URL and returns the parsed HTML content
def get_page_content(url):
    try:
        response = requests.get(url)
        response.raise_for_status()  # May raise an HTTPError
        return BeautifulSoup(response.content, 'html.parser')
    except requests.exceptions.RequestException as e:
        print(f"Error fetching {url}: {e}")
        return None

# A list to store the extracted data
product_data = []

for url in urls:
    print(f"Scraping {url}...")
    soup = get_page_content(url)
    
    if soup is None:
        continue  # Skip this URL in case of request failure
    
    # Assuming products are within a specific section (update selectors as per actual HTML structure)
    products = soup.find_all('div', class_='product-listing')
    
    for product in products:
        try:
            name = product.find('h2', class_='product-name').get_text(strip=True)
        except AttributeError:
            name = None
        
        try:
            price = product.find('span', class_='product-price').get_text(strip=True)
        except AttributeError:
            price = None

        try:
            description = product.find('p', class_='product-description').get_text(strip=True)
        except AttributeError:
            description = None

        try:
            rating = product.find('span', class_='product-rating').get_text(strip=True)
        except AttributeError:
            rating = None
        
        # Append the data to the list
        product_data.append({
            'product_name': name,
            'price': price,
            'description': description,
            'rating': rating
        })
    
    # Respect the website's server load
    time.sleep(1)

# Convert list to DataFrame
df = pd.DataFrame(product_data)

# Display the first few rows of the DataFrame
print(df.head())

# You may choose to save the results to a file
# df.to_csv('products.csv', index=False)