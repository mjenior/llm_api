# Code generated by gpt-4o-mini

import requests
from bs4 import BeautifulSoup
import pandas as pd
import time

def scrape_product_data(url):
    response = requests.get(url)
    if response.status_code == 200:
        soup = BeautifulSoup(response.content, 'html.parser')
        products = []

        for product in soup.find_all('div', class_='product'):
            name = product.find('h2').text
            price = product.find('span', class_='price').text
            description = product.find('p', class_='description').text
            rating = product.find('span', class_='rating')
            rating = rating.text if rating else 'No Rating'
            products.append({'name': name, 'price': price, 'description': description, 'rating': rating})

        return pd.DataFrame(products)
    else:
        print(f"Error: Unable to fetch page {url}")
        return pd.DataFrame()

if __name__ == "__main__":
    url = "http://example.com/products"  # Replace with actual URL
    df = scrape_product_data(url)
    print(df)import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
from typing import List, Dict, Any

def scrape_product_data(url: str) -> pd.DataFrame:
    """
    Scrapes product data from the specified e-commerce URL and returns a DataFrame.

    Parameters:
    - url (str): The URL of the product listing page.

    Returns:
    - pd.DataFrame: A DataFrame containing product information, or an empty DataFrame on error.
    """
    try:
        response = requests.get(url)
        response.raise_for_status()  # Raise an error for bad responses
    except requests.RequestException as e:
        print(f"Error fetching {url}: {e}")
        return pd.DataFrame()

    soup = BeautifulSoup(response.content, 'html.parser')
    products = extract_product_info(soup)

    return pd.DataFrame(products)


def extract_product_info(soup: BeautifulSoup) -> List[Dict[str, Any]]:
    """
    Extracts product information from the BeautifulSoup parsed HTML.

    Parameters:
    - soup (BeautifulSoup): The BeautifulSoup object containing the parsed HTML.

    Returns:
    - List[Dict[str, Any]]: A list of dictionaries, each representing a product.
    """
    products = []
    for product in soup.find_all('div', class_='product'):
        name = product.find('h2').get_text(strip=True)
        price = product.find('span', class_='price').get_text(strip=True)
        description = product.find('p', class_='description').get_text(strip=True)
        rating = product.find('span', class_='rating')
        rating = rating.get_text(strip=True) if rating else 'No Rating'
        
        products.append({
            'name': name,
            'price': price,
            'description': description,
            'rating': rating
        })
    
    return products


if __name__ == "__main__":
    # User reminder to check legality of scraping
    print("Please ensure that scraping this website complies with its terms of service.")
    
    url = "http://example.com/products"  # Placeholder URL
    df = scrape_product_data(url)
    
    # Simulating delays to respect server load
    time.sleep(2)
    
    print(df)